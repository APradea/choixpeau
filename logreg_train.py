#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Mon Nov  7 15:14:01 2022@author: anthelme"""import numpy as np import csv import pandas as pdimport operation_data as odimport matplotlib.pyplot as plt import sysfrom lib_math import ft_countSELECTED_FEATURES = ["Defense Against the Dark Arts","Divination","Charms", "History of Magic", "Ancient Runes", "Flying"]class LogRegTrain():        def __init__(self, X_train , y_train, iteration = 500, alpha = 0.15):        self.X = np.insert(np.array(X_train), 0, np.ones(len(X_train)), axis=1)        self.y_train = y_train        self.iteration = iteration        self.alpha = alpha                self.y = np.zeros(len(y_train))        self.theta = {}        self.costs = {}                    def save_csv(self):        filename = './theta.csv'        f = open(filename, 'w+')        w = csv.writer(f)        w.writerow(self.theta.keys())        for i in range(len(SELECTED_FEATURES) + 1):            row = [self.theta[house][i] for house in self.theta.keys()]            w.writerow(row)                    # replace les données en 0 et 1    def sigmoid(self, X):        return 1 / (1 + np.exp(-X))        # la logistic reg s'applique sur une maison contre les autres    def logistic_regr(self):        # m etant le nombre d'eleves et n le nombre de cours (features) choisis        m, n  = np.shape(self.X)                # on remplit un tableau de zeros         theta = np.zeros(n)        # une liste c'est un hash        cost_list = list()                for i in range (self.iteration):            # produit matriciel entre les notes et tetha sommes de tethaYX * noteYX            H = np.dot(self.X, theta)            Z = self.sigmoid(H)                        # distance entre la prediction Z et les vrai valeurs self.y            # deriv_tetha c'est la pente qui nous permet de converger            # produit matriciel = 5 valeurs             deriv_theta = (1 / m) * np.dot(self.X.T, Z - self.y)                        # alpha etant le learning rate, un tetha par cours             theta = theta - self.alpha * deriv_theta                        cost_i = np.dot(self.y.T,np.log(Z)) + np.log (1 - Z) - np.dot(self.y.T,np.log(1 - Z))            cost_list.append((-1 / m) * cost_i)                    return theta, cost_list        # pour chaque maison, on attribu un 1 si on trouve la maison donnant le     # poids d'une maison à 1 contre toutes les autres maisons (0)    def one_vs_all(self):        # .unique() nous permet d'avoir une seul occurence de chaque sortie donc        # ici les 4 maisons        # Equivalent to : y = self.y_train.map(lambda x: 0 if x != house else 1)        for house in self.y_train.unique():            i = 0            for value in self.y_train:                if value == house:                    self.y[i] = 1                else:                    self.y[i] = 0                i += 1            self.theta[house], self.costs[house] = self.logistic_regr()        self.save_csv()        def sigmoid(X):    return 1 / (1 + np.exp(-X))        def logreg_train(file):        try:        data_train = pd.read_csv(file)    except:        raise Exception("File not found or error while opening the file")        df =  data_train[SELECTED_FEATURES]        # on norme les valeurs de df (ce qui crée une copie de df)    df = od.norm_values(df)        # comme les valeurs sont normées, mettre un zero à la place des     # chiffres manquants revient à attribuer la moyenne    df = od.replace_missing_values_by_zeros(df)        # on recupere la colone corespondant aux maisons    y_train = data_train['Hogwarts House']        # on initialize la classe LogRegTrain pour preparer les données    logreg = LogRegTrain(df, y_train)        logreg.one_vs_all()if __name__ == "__main__":    if ft_count(sys.argv) > 1:        logreg_train(sys.argv[1])    else:        print("put a file plz")file = ('/Users/anthelmepradeau/Desktop/Travail Victor/choixpeau/datasets/dataset_train.csv')